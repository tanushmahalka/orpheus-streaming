[cerebrium.deployment]
name = "orpheus-trt-server"
python_version = "3.12"
docker_base_image_url = "nvidia/cuda:12.8.1-devel-ubuntu22.04"
disable_auth = true
include = ['./*', 'main.py', 'cerebrium.toml']
exclude = ['.*']
use_uv = true

[cerebrium.hardware]
cpu = 3
memory = 12
compute = "AMPERE_A10"
provider = "aws"
region = "us-east-1"

[cerebrium.dependencies.apt]
libopenmpi-dev = "latest"
libopenblas-base = "latest"
libomp-dev = "latest"

[cerebrium.scaling]
min_replicas = 0
max_replicas = 2
cooldown = 30
replica_concurrency = 1
scaling_metric = "concurrency_utilization"

[cerebrium.build]
shell_commands = [
  "uv pip install tensorrt_llm --extra-index-url https://pypi.nvidia.com",
  "bash start.sh"
]